# -*- coding: utf-8 -*-
"""NN1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WCBDrK-m2JNeKCypWMR6svgANdiD-cj8
"""

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
  return 1/(1+np.exp(-x))
x=np.linspace(-10,10,100)
plt.figure(figsize=(8,6))
plt.subplot(2,2,2)
plt.plot(x, sigmoid (x))
plt.title("sigmoid activation function")
plt.grid(alpha=0.3)

import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

np.random.seed(10)
#it would stop generating new random number means only one type random number is generated,u can choose any integer 10,1,etc but different integer gives different values
num_samples=1000
x=np.random.rand(num_samples,3)*np.array([24,10,60])
#1000 rows and 3 columns,1st column range from 0 to 24 and 2nd column 0 to 10 and 3rd column 0 to 60 because random number generat from 0 to 1
y=np.random.rand(num_samples)*100

pd.DataFrame(x, columns=['hours_of_sleep',"cups_of_coffe","travel_time"]).head()

def create_custom_model():
   #input
   inputs= keras.Input(shape=(3,))
   #hidden layer
   x=layers.Dense(2, activation="sigmoid")(inputs)
#2 hidden nodes and connecting with inputs
   #output
   outputs=layers.Dense(1, activation="linear")(x)
#linear means regression any no. and segmoid means 0 or 1
   model = keras.Model(inputs=inputs,outputs=outputs)
   #connect all
   return model

model=create_custom_model()
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss="mean_squared_error")
#inplace of Adam u can use many ...

print(model.summary())

histry =model.fit(x,y,epochs=150,batch_size=32, validation_split=0.20,verbose=1)
#epochs=150 → The model will loop through your dataset 150 times.

#batch_size=32 → Instead of processing the whole dataset at once, it processes 32 samples at a time, then updates weights.

#validation_split=0.20 → 20% of your dataset is automatically set aside for validation.

#verbose=1 → Prints progress bar and loss/accuracy per epoch.i.e the way print will lock like (output will be same)

test_loss=model.evaluate(x,y, verbose=1)
print(f"Test Loss={test_loss}")

plt.figure(figsize=(8,6))
plt.plot(histry.history['loss'],label='Training Loss')
plt.plot(histry.history['val_loss'],label='Variation Loss')
#history in in built function it contains loss,val_loss,accuracy,val_accuracy,
plt.title("Train vs validation loss graph")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid(alpha=0.4)
plt.legend()

sample_data=np.array([[7,3,25]])
prediction=model.predict(sample_data)
prediction